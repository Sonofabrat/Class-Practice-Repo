{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paige Haring\n",
    "\n",
    "peh40@pitt.edu\n",
    "\n",
    "10/16/17\n",
    "\n",
    "This notebook is my progress following along with this tutorial on scikit-learn.org: http://scikit-learn.org/dev/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import nltk\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting directory to where my nltk data has the movie reviews corpus\n",
    "nltk.data.path #gotta find it first...\n",
    "movie_dir = \"/Users/Paige/nltk_data/corpora/movie_reviews/\"\n",
    "\n",
    "#load all of the files in the movie_reviews corpus as training data\n",
    "movie_train = load_files(movie_dir, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is movie_train?\n",
    "type(movie_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(movie_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target_names #These are the labels or classes we will want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv405_21868.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv190_27052.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv132_5618.txt',\n",
       "       ...,\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/pos/cv653_19583.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv559_0057.txt',\n",
       "       '/Users/Paige/nltk_data/corpora/movie_reviews/neg/cv684_12727.txt'], \n",
       "      dtype='<U64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many reviews do we have?\n",
    "len(movie_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"any remake of an alfred hitchcock film is at best an uncertain project , as a perfect murder illustrates . \\nfrankly , dial m for murder is not one of the master director's greatest efforts , so there is ample room for improvement . \\nunfortunately , instead of updating the script , ironing out some of the faults , and speeding up the pace a little , a perfect murder has inexplicably managed to eliminate almost everything that was worthwhile about dial m for murder , leaving behind the nearly- unw\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the last review and the information we have about it.\n",
    "movie_train.data[-1][:500]\n",
    "\n",
    "#Seems like it's about the film Dial M for Murder and it doesn't look too good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.target[-1] #Yep. That's negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "pprint%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = ['Hello, how are you today?', 'Just fine!', 'How are the wife and kids?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are forcing CountVectorizer to use nltk's word tokenizer because it's better for us. It doesn't ignore stopwords and punctuation like the default does.\n",
    "foovec = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit_transform in module sklearn.feature_extraction.text:\n",
      "\n",
      "fit_transform(raw_documents, y=None) method of sklearn.feature_extraction.text.CountVectorizer instance\n",
      "    Learn the vocabulary dictionary and return term-document matrix.\n",
      "    \n",
      "    This is equivalent to fit followed by transform, but more efficiently\n",
      "    implemented.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    raw_documents : iterable\n",
      "        An iterable which yields either str, unicode or file objects.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : array, [n_samples, n_features]\n",
      "        Document-term matrix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(foovec.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 6, ',': 1, 'how': 7, 'are': 4, 'you': 13, 'today': 11, '?': 2, 'just': 8, 'fine': 5, '!': 0, 'the': 10, 'wife': 12, 'and': 3, 'kids': 9}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sents_sounts is a word vector with infomation about the word frequencies for each sent in sents\n",
    "sents_counts = foovec.fit_transform(sents)\n",
    "\n",
    "#Calling fit_transform modified foovec\n",
    "#foovec now has an attribute called vocabulary that is kind of like a dictionary. The keys are the unique tokens\n",
    "#The values are a unique, numerical id\n",
    "foovec.vocabulary_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents_counts has a dimension of 3 (document count) by 14 (# of unique words)\n",
    "sents_counts.shape\n",
    "\n",
    "#Note these 14 elements correspond to the id in foovec.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_counts.toarray()\n",
    "#Example:\n",
    "#The indexes with ones in the first list are 1, 2, 4, 6, 7, 11, 13\n",
    "#Those id's correspond to the words: ',', '?', 'are', 'hello', 'how', 'today', 'you'\n",
    "#Those are the words in the first sentence! sents_counts is essentially an inventory of which of the total number of words in sents\n",
    "#are in each sentence in sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "sents_tfidf = tfidf_transformer.fit_transform(sents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.41756662,  0.31757018,  0.        ,  0.31757018,\n",
       "         0.        ,  0.41756662,  0.31757018,  0.        ,  0.        ,\n",
       "         0.        ,  0.41756662,  0.        ,  0.41756662],\n",
       "       [ 0.57735027,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.57735027,  0.        ,  0.        ,  0.57735027,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.31757018,  0.41756662,  0.31757018,\n",
       "         0.        ,  0.        ,  0.31757018,  0.        ,  0.41756662,\n",
       "         0.41756662,  0.        ,  0.41756662,  0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF values\n",
    "# raw counts have been normalized against document length, \n",
    "# terms that are found across many docs are weighted down\n",
    "sents_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
