{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning 2\n",
    "Na-Rae Han, 10/19/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General machine learning work flow:\n",
    "1. Choose a class of model\n",
    "2. Choose model hyperparameters\n",
    "3. Fit the model to the training data (\"training\")\n",
    "4. Use the model to predict labels for new data\n",
    "    - If labels are known (test data, aka 'gold' data), evaluate the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three types of ML:\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.01-what-is-machine-learning.html\n",
    "\n",
    "1. Regression: predicting continuous values\n",
    "2. Classification: predicting discrete labels\n",
    "3. **Clustering: inferring labels on unlabeled data**  <-- This one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Turns on/off pretty printing \n",
    "%pprint\n",
    "\n",
    "# Every returned Out[] is displayed, not just the last one. \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn               # sklearn is the ML package we will use\n",
    "import seaborn as sns        # seaborn graphical package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: a type of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using sklearn's pre-loaded data set \"20 Newsgroups\" \n",
    "- Code below is adapted from sklearn's official tutorial: \n",
    "  http://scikit-learn.org/stable/auto_examples/text/document_clustering.html \n",
    "\n",
    "Topic-based clustering is our goal:  \n",
    "- Given a set of documents that are written on 4 topics, can they be grouped into 4 clusters? \n",
    "\n",
    "We will try **K-means clustering** method. \n",
    "- A good introduction article: https://www.datascience.com/blog/k-means-clustering\n",
    "- sklearn's documentation: http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TfidfVectorizer is essentially CountVectorizer + TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# We will use the same 4 categories\n",
    "cats = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']\n",
    "\n",
    "# Not using train-test split. Because this is un-supervised! \n",
    "dataset = fetch_20newsgroups(subset='all', categories=cats, shuffle=True, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'sklearn.datasets.base.Bunch'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'description', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: vis@world.std.com (Tom R Courtney)\\nSubject: Re: Space Marketing would be wonderfull.\\nOrganization: The World Public Access UNIX, Brookline, MA\\nLines: 17\\n\\nIn some sense, I think that the folks who think the idea is wonderful, and the\\nfolks who want to boycott anyone who has anything to do with this project are\\nboth right.\\n\\nThat is, I think that space advertising is an interesting idea, and if someone\\nwants to try it out, more power to them. However, a company may discover that\\nthe cost of launch is not the only cost of advertising, and a company who \\ngauged that ill will would lose them more revenue than the advertising would\\ngain might decide to bow out of the project.\\n\\nI got incensed when I read that Carl Sagan called this idea an \"abomination.\" \\nI don\\'t think that word means what he thinks it does. Children starving in the\\nrichest country in the world is an abomination; an ad agency is at worst just\\nin poor taste.\\n\\nTom Courtney\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 3, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target\n",
    "dataset.target[5]\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# In our case, WE KNOW TRUE VALUE OF K: 4 topics. \n",
    "# But in many real-life use cases, true number of clusters will not be known,\n",
    "#  and user must experiment with different K values. \n",
    "\n",
    "true_k = np.unique(dataset.target).shape[0]\n",
    "print(true_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore words found in over 50% of documents, ignore words found in just 1 document. \n",
    "# 1000 most frequent words, remove stop words. \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 31 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 204)\t0.0672523411448\n",
      "  (0, 746)\t0.105033387862\n",
      "  (0, 180)\t0.137895061559\n",
      "  (0, 899)\t0.318946488968\n",
      "  (0, 826)\t0.194510523256\n",
      "  (0, 289)\t0.0790109160299\n",
      "  (0, 292)\t0.0753453600121\n",
      "  (0, 474)\t0.0720597593222\n",
      "  (0, 382)\t0.117968021464\n",
      "  (0, 711)\t0.103870512588\n",
      "  (0, 957)\t0.0980917306138\n",
      "  (0, 982)\t0.271846319562\n",
      "  (0, 697)\t0.124447255719\n",
      "  (0, 53)\t0.118728321999\n",
      "  (0, 923)\t0.138473219002\n",
      "  (0, 16)\t0.124447255719\n",
      "  (0, 787)\t0.131302647881\n",
      "  (0, 887)\t0.313694855686\n",
      "  (0, 429)\t0.351672218256\n",
      "  (0, 689)\t0.265838807771\n",
      "  (0, 449)\t0.130831997331\n",
      "  (0, 959)\t0.153887024417\n",
      "  (0, 909)\t0.119059351145\n",
      "  (0, 671)\t0.12915907751\n",
      "  (0, 216)\t0.297109201319\n",
      "  (0, 235)\t0.280127897997\n",
      "  (0, 495)\t0.14325935292\n",
      "  (0, 160)\t0.116086406394\n",
      "  (0, 977)\t0.120763749157\n",
      "  (0, 553)\t0.122679382187\n",
      "  (0, 60)\t0.155757332972\n"
     ]
    }
   ],
   "source": [
    "X[5]\n",
    "print(X[5])\n",
    "# 1x1000? \"sparse matrix\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'com'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'children'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('space')\n",
    "vectorizer.get_feature_names()[204]\n",
    "vectorizer.get_feature_names()[180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation complete. Time to apply K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 6419.988\n",
      "Iteration  1, inertia 3344.121\n",
      "Iteration  2, inertia 3323.059\n",
      "Iteration  3, inertia 3317.488\n",
      "Iteration  4, inertia 3314.543\n",
      "Iteration  5, inertia 3311.615\n",
      "Iteration  6, inertia 3308.582\n",
      "Iteration  7, inertia 3307.064\n",
      "Iteration  8, inertia 3306.856\n",
      "Iteration  9, inertia 3306.810\n",
      "Iteration 10, inertia 3306.778\n",
      "Iteration 11, inertia 3306.772\n",
      "Iteration 12, inertia 3306.766\n",
      "Iteration 13, inertia 3306.764\n",
      "Iteration 14, inertia 3306.762\n",
      "Converged at iteration 14: center shift 0.000000e+00 within tolerance 9.553371e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=4, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.399\n",
      "Completeness: 0.473\n",
      "V-measure: 0.433\n",
      "Adjusted Rand-Index: 0.344\n",
      "Silhouette Coefficient: 0.018\n"
     ]
    }
   ],
   "source": [
    "# A bunch of metrics that compare target labels and labels as assigned by KM. \n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(dataset.target, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(dataset.target, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(dataset.target, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: god jesus people christian church bible christians christ com believe\n",
      "Cluster 1: space nasa henry gov toronto alaska moon shuttle launch zoo\n",
      "Cluster 2: com university graphics posting host nntp thanks article know computer\n",
      "Cluster 3: access digex sandvik pat net kent com apple prb newton\n"
     ]
    }
   ],
   "source": [
    "# Top terms (\"features\") as ranked by centroids\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 1, 0, 2, 1, 2, 0, 1, 0, 3, 2, 2, 0, 2, 3, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 3, 2, 0, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_[:20]        # Cluster labels as assigned by KMeans\n",
    "dataset.target[:20]    # These are the real target labels\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2. Let's try 3 clusters this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 6446.670\n",
      "Iteration  1, inertia 3353.373\n",
      "Iteration  2, inertia 3336.845\n",
      "Iteration  3, inertia 3335.146\n",
      "Iteration  4, inertia 3334.940\n",
      "Iteration  5, inertia 3334.894\n",
      "Iteration  6, inertia 3334.860\n",
      "Iteration  7, inertia 3334.833\n",
      "Iteration  8, inertia 3334.820\n",
      "Iteration  9, inertia 3334.811\n",
      "Iteration 10, inertia 3334.803\n",
      "Iteration 11, inertia 3334.796\n",
      "Iteration 12, inertia 3334.783\n",
      "Iteration 13, inertia 3334.774\n",
      "Iteration 14, inertia 3334.766\n",
      "Iteration 15, inertia 3334.754\n",
      "Iteration 16, inertia 3334.747\n",
      "Iteration 17, inertia 3334.736\n",
      "Iteration 18, inertia 3334.729\n",
      "Iteration 19, inertia 3334.726\n",
      "Converged at iteration 19: center shift 0.000000e+00 within tolerance 9.553371e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=3, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km2 = KMeans(n_clusters=3, init='k-means++', max_iter=100, n_init=1, verbose=True)\n",
    "km2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: god jesus com people christian church bible christians christ don\n",
      "Cluster 1: space nasa access henry digex gov pat toronto alaska com\n",
      "Cluster 2: com graphics university posting host nntp thanks image computer know\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km2.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(3):\n",
    "    print(\"Cluster %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()\n",
    "# Are the clusters looking better? \n",
    "# CAVEAT: could be local optimum, re-run to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 3, 2, 0, 3, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.space', 'soc.religion.christian', 'talk.religion.misc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km2.labels_[:20]        # Cluster labels as assigned by KMeans\n",
    "dataset.target[:20]     # These are the real target labels\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Newsgroup label -> KM label. Will need to adjust. \n",
    "labelmap = {0:2, 1:1, 2:0, 3:0}\n",
    "\n",
    "target_conv = [labelmap[x] for x in dataset.target]\n",
    "target_conv[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1331,    6,  288],\n",
       "       [  10,  729,  248],\n",
       "       [   3,    9,  961]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(target_conv, km2.labels_)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot object at 0x000002865529DF60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text object at 0x00000286552C7908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text object at 0x00000286552A81D0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFXCAYAAAAWMQ0YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure object at 0x00000286552C8438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true group')\n",
    "plt.ylabel('predicted group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can we produce nifty clustering visuals\n",
    "such as the ones in tutorial/documentation: \n",
    "- https://www.datascience.com/blog/k-means-clustering\n",
    "- http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_iris_004.png\n",
    "\n",
    "??\n",
    "\n",
    "Answer: **NO**. The examples deal with 2 and 3 dimensions(features) respectively, and therefore can be mapped in 2- and 3-dimensions. Our model involves 1000 (!) dimensions, therefore impossible to plot that way. Handling language data often involves HUGE dimensions, coming from individual lexical items each of which constitutes its own feature dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too Many Dimensions?\n",
    "This is where **PCA** (**Principal Component Analysis**) comes in. PCA is a method for reducing dimensions; it identifies dimensions/features that are not predictive and therefore can be discarded in model building. \n",
    "- Textbook chapter: https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html\n",
    "\n",
    "Suppose you have a spreadsheet of people's age, years of experience, years of education, zip code, gender, height, weight, shoe size, favorite color, and finally their salary. In predicting someone's salary, which features will be most predictive and which the least (or not at all)? PCA identifies the latter, helping to reduce dimensions in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on new, made up examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sending a payload to the ISS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-07658e64bc1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sending a payload to the ISS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'I met Santa Claus once'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#??? Error? Why?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    958\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'sending a payload to the ISS'"
     ]
    }
   ],
   "source": [
    "tests = ['sending a payload to the ISS', 'I met Santa Claus once']\n",
    "preds = km2.predict(tests)\n",
    "print(preds)\n",
    "#??? Error? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "tests = ['sending a payload to the ISS space astronaut earth orbit', \n",
    "         'pray jesus I met Santa Claus once']\n",
    "tests_tfidf = vectorizer.transform(tests)    # Yep, need this step\n",
    "preds = km2.predict(tests_tfidf)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
